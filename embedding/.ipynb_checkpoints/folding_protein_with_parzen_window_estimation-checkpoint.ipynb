{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "window_width = 2\n",
    "grid_cell_size = 1\n",
    "grid_X_size = 18\n",
    "grid_Y_size = 18\n",
    "grid_Z_size = 18\n",
    "coord_X_min = -10\n",
    "coord_Y_min = -10\n",
    "coord_Z_min = -10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def protein_grid(grid_X_size,grid_Y_size,grid_Z_size,coord_X_min,coord_Y_min,coord_Z_min):\n",
    "    \n",
    "    # All the possible x,y,z coordinates for x,y,z axis in protein grid.\n",
    "    x_possible = [(x*grid_cell_size)+coord_X_min for x in range(grid_X_size)]\n",
    "    y_possible = [(y*grid_cell_size)+coord_Y_min for y in range(grid_Y_size)]\n",
    "    z_possible = [(z*grid_cell_size)+coord_Z_min for z in range(grid_Z_size)]\n",
    "    \n",
    "    # Extract all the possible 3 coordinates for 3D protein grid.\n",
    "    protein_coord_grid = [[x,y,z]for x in x_possible for y in y_possible for z in z_possible]\n",
    "    \n",
    "    # Reshape to extract 4D structure.\n",
    "    protein_coord_grid = np.array(protein_coord_grid).reshape((18,18,18,3))\n",
    "    \n",
    "    # Returning 4D protein coordinate grid with shape (18,18,18,3).\n",
    "    return protein_coord_grid\n",
    "\n",
    "def zero_dict_channel_21(grid_X_size,grid_Y_size,grid_Z_size):\n",
    "    # Create an empty dictionary.\n",
    "    tensor_dict_channel_21 = {}\n",
    "    \n",
    "    # Initialize all the 21 functional atoms by 3D zero grid of shape (18,18,18).\n",
    "    for i in range(1,22):\n",
    "        tensor_dict_channel_21[i] = np.zeros((grid_X_size,grid_Y_size,grid_Z_size))\n",
    "        \n",
    "    # Returning functional atoms dictionary with 3D zero grid (18,18,18) as value.\n",
    "    # It's a 4D strucure of shape (21,18,18,18).\n",
    "    return tensor_dict_channel_21\n",
    "\n",
    "def change_dict_tensor(protein_dict,protein_grid_4D,zero_dict_4D,window_width):\n",
    "    # Input Parameters:\n",
    "    # protein_dict contains all the atoms present in protein with their x,y,z coordinates.\n",
    "    # protein_grid_4D (18,18,18,3) contains 4D protein coordinate grid.\n",
    "    # zero_dict_4D (21,18,18,18) contains functional atoms dictionary with 3D zero grid of shape (18,18,18) as value.\n",
    "    # window_width for parzen window estimation\n",
    "    \n",
    "    # Deep_copy the functional atoms dictionary with 3D zero grid of shape (18,18,18) as value.\n",
    "    # It's a 4D strucure of shape (21,18,18,18), we will update this using parzen window.\n",
    "    tensor_dict = copy.deepcopy(zero_dict_4D)\n",
    "    \n",
    "    # Update all the functional atoms 3D grid, which has values in the protein by adding the \n",
    "    # contribution to their corresponding 3D grid.\n",
    "       \n",
    "    for atom in protein_dict:\n",
    "        \n",
    "        # Intialize 3D zero grid to update a functional atom 3D grid.\n",
    "        contribution = np.zeros(tensor_dict[atom].shape)\n",
    "        \n",
    "        # Check all the occurences of the functional atom to update the functional atom 3D grid.\n",
    "        for coordinates in protein_dict[atom]:\n",
    "            \n",
    "            # Parzen window implementation.\n",
    "            distance_sq = np.sum(np.square(protein_grid_4D - coordinates),axis=3)\n",
    "            contribution += np.exp(-distance_sq/(2*(window_width**2)))\n",
    "            \n",
    "        # Update the functional atom 3D grid.\n",
    "        tensor_dict[atom] += contribution\n",
    "        \n",
    "    # Create an empty tensor\n",
    "    tensor = []\n",
    "    \n",
    "    # Add the 3D grid of all the 21 functional atoms\n",
    "    for i in range(1,22):\n",
    "        tensor.append(tensor_dict[i])\n",
    "        \n",
    "    # Returning 4D numpy array of tensor with shape (21,18,18,18)\n",
    "    return np.array(tensor)\n",
    "            \n",
    "\n",
    "def file_data(file_path,file_name,protein_grid_3D,zero_dict_4D,window_width,data_path,label_path):\n",
    "    # Input parameters:\n",
    "    # file_name contains name of the text file.\n",
    "    # protein_grid_3D,zero_dict_4D and window_width  are used when call change_dict_tensor function for each protein.\n",
    "    \n",
    "    \n",
    "    # Create empty lists for protein labels and tensors(21,18,18,18) present in the file.\n",
    "    protein_label = []\n",
    "    protein_data = []\n",
    "    \n",
    "    # Read text file\n",
    "    with open(file_path + file_name + \".txt\",\"r\") as fp:\n",
    "        \n",
    "        # Each line in the file represents a protein.\n",
    "        for line in fp.read().splitlines():\n",
    "            \n",
    "            # Create an empty dictionary\n",
    "            protein_dict = {}\n",
    "            line = line.strip().split(\"\\t\")\n",
    "            \n",
    "            # Store Label in the protein_label list\n",
    "            protein_label += [line.pop(0)]\n",
    "            \n",
    "            # Update the protein_dict dictionary by adding (x,y,z) coordinates belonging to functional atoms.\n",
    "            for atom in line:\n",
    "                atom = atom.split(\",\")\n",
    "                protein_dict[int(atom[0])] = protein_dict.get(int(atom[0]),[]) + [[float(cord) for cord in atom[1:]]] \n",
    "                \n",
    "            # Store tensor in the protein_data list\n",
    "            protein_data.append(change_dict_tensor(protein_dict,protein_grid_3D,zero_dict_4D,window_width))\n",
    "            \n",
    "    # Storing the data and label files in numpy format extracting from the text file\n",
    "    #return np.array(protein_data),np.array(protein_label)\n",
    "    \n",
    "    np.save(data_path+ file_name + \"_data.npy\", np.array(protein_data))\n",
    "    np.save(label_path+ file_name + \"_label.npy\", np.array(protein_label))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------ 1\n",
      "------------------ 2\n",
      "------------------ 3\n",
      "------------------ 4\n",
      "------------------ 5\n",
      "------------------ 6\n",
      "------------------ 7\n",
      "------------------ 8\n",
      "------------------ 9\n",
      "------------------ 10\n",
      "------------------ 11\n",
      "------------------ 12\n",
      "------------------ 13\n",
      "------------------ 14\n",
      "------------------ 15\n",
      "------------------ 16\n",
      "------------------ 17\n",
      "------------------ 18\n",
      "------------------ 19\n",
      "------------------ 20\n",
      "------------------ 21\n",
      "------------------ 22\n",
      "------------------ 23\n",
      "------------------ 24\n",
      "------------------ 25\n",
      "------------------ 26\n",
      "------------------ 27\n",
      "------------------ 28\n",
      "------------------ 29\n",
      "------------------ 30\n",
      "------------------ 31\n",
      "------------------ 32\n",
      "------------------ 33\n",
      "------------------ 34\n",
      "------------------ 35\n",
      "------------------ 36\n",
      "------------------ 37\n",
      "------------------ 38\n",
      "------------------ 39\n",
      "------------------ 40\n",
      "------------------ 41\n",
      "------------------ 42\n",
      "------------------ 43\n",
      "------------------ 44\n",
      "------------------ 45\n",
      "------------------ 46\n",
      "------------------ 47\n",
      "------------------ 48\n",
      "------------------ 49\n",
      "------------------ 50\n",
      "------------------ 51\n",
      "------------------ 52\n",
      "------------------ 53\n",
      "------------------ 54\n",
      "------------------ 55\n",
      "------------------ 56\n",
      "------------------ 57\n",
      "------------------ 58\n",
      "------------------ 59\n",
      "------------------ 60\n",
      "------------------ 61\n",
      "------------------ 62\n",
      "------------------ 63\n",
      "------------------ 64\n",
      "------------------ 65\n",
      "------------------ 66\n",
      "------------------ 67\n",
      "------------------ 68\n",
      "------------------ 69\n",
      "------------------ 70\n",
      "------------------ 71\n",
      "------------------ 72\n",
      "------------------ 73\n",
      "------------------ 74\n",
      "------------------ 75\n",
      "------------------ 76\n",
      "------------------ 77\n",
      "------------------ 78\n",
      "------------------ 79\n",
      "------------------ 80\n",
      "------------------ 81\n",
      "------------------ 82\n",
      "------------------ 83\n",
      "------------------ 84\n",
      "------------------ 85\n",
      "------------------ 86\n",
      "------------------ 87\n",
      "------------------ 88\n",
      "------------------ 89\n",
      "------------------ 90\n",
      "------------------ 91\n",
      "------------------ 92\n",
      "------------------ 93\n",
      "------------------ 94\n",
      "------------------ 95\n",
      "------------------ 96\n",
      "------------------ 97\n",
      "------------------ 98\n",
      "------------------ 99\n",
      "------------------ 100\n",
      "------------------ 101\n",
      "------------------ 102\n",
      "------------------ 103\n",
      "------------------ 104\n",
      "------------------ 105\n",
      "------------------ 106\n",
      "------------------ 107\n",
      "------------------ 108\n",
      "------------------ 109\n",
      "------------------ 110\n",
      "------------------ 111\n",
      "------------------ 112\n",
      "------------------ 113\n",
      "------------------ 114\n",
      "------------------ 115\n",
      "------------------ 116\n",
      "------------------ 117\n",
      "------------------ 118\n",
      "------------------ 119\n",
      "------------------ 120\n",
      "------------------ 121\n",
      "------------------ 122\n",
      "------------------ 123\n",
      "------------------ 124\n",
      "------------------ 125\n",
      "------------------ 126\n",
      "------------------ 127\n",
      "------------------ 128\n",
      "------------------ 129\n",
      "------------------ 130\n",
      "------------------ 131\n",
      "------------------ 132\n",
      "------------------ 133\n",
      "------------------ 134\n",
      "------------------ 135\n",
      "------------------ 136\n",
      "------------------ 137\n",
      "------------------ 138\n",
      "------------------ 139\n",
      "------------------ 140\n",
      "------------------ 141\n",
      "------------------ 142\n",
      "------------------ 143\n",
      "------------------ 144\n",
      "------------------ 145\n",
      "------------------ 146\n",
      "------------------ 147\n",
      "------------------ 148\n",
      "------------------ 149\n",
      "------------------ 150\n",
      "------------------ 151\n",
      "------------------ 152\n",
      "------------------ 153\n",
      "------------------ 154\n",
      "------------------ 155\n",
      "------------------ 156\n",
      "------------------ 157\n",
      "------------------ 158\n",
      "------------------ 159\n",
      "------------------ 160\n",
      "------------------ 161\n",
      "------------------ 162\n",
      "------------------ 163\n",
      "------------------ 164\n",
      "------------------ 165\n",
      "------------------ 166\n",
      "------------------ 167\n",
      "------------------ 168\n",
      "------------------ 169\n",
      "------------------ 170\n",
      "------------------ 171\n",
      "------------------ 172\n",
      "------------------ 173\n",
      "------------------ 174\n",
      "------------------ 175\n",
      "------------------ 176\n",
      "------------------ 177\n",
      "------------------ 178\n",
      "------------------ 179\n",
      "------------------ 180\n",
      "------------------ 181\n",
      "------------------ 182\n",
      "------------------ 183\n",
      "------------------ 184\n",
      "------------------ 185\n",
      "------------------ 186\n",
      "------------------ 187\n",
      "------------------ 188\n",
      "------------------ 189\n",
      "------------------ 190\n",
      "------------------ 191\n",
      "------------------ 192\n",
      "------------------ 193\n",
      "------------------ 194\n",
      "------------------ 195\n",
      "------------------ 196\n",
      "------------------ 197\n",
      "------------------ 198\n",
      "------------------ 199\n",
      "------------------ 200\n"
     ]
    }
   ],
   "source": [
    "# Extracting a dictionary to extract the 3D zero matrix for all the 21 atoms \n",
    "zero_channel21_4D_val = zero_dict_channel_21(grid_X_size,grid_Y_size,grid_Z_size)\n",
    "\n",
    "# Extracting a 4D protein coordinate grid with shape (18,18,18,3)\n",
    "protein_grid_3D_val = protein_grid(grid_X_size,grid_Y_size,grid_Z_size,coord_X_min,coord_Y_min,coord_Z_min)\n",
    "\n",
    "# Path of text files and storing tensors/labels\n",
    "path = \"/home/atharva/Desktop/2.coor/\"\n",
    "path_tensor = \"/home/atharva/Desktop/tensor_data/\"\n",
    "path_label = \"/home/atharva/Desktop/tensor_label/\"\n",
    "\n",
    "# List of all the files (10163 files)\n",
    "file_list = os.listdir(path)\n",
    "count = 0\n",
    "\n",
    "#  I have converted 1000 files into 5D structure ( 5D numpy array) and able to extract\n",
    "# 460,733 samples of shape (21,18,18,18) \n",
    "for txt_file in file_list[:1000]:\n",
    "    if txt_file.endswith(\".txt\"):\n",
    "        txt_file = txt_file.split('.')[0]\n",
    "        # Change txt file into numpy array\n",
    "        file_data(path,txt_file,protein_grid_3D_val,zero_channel21_4D_val,window_width,path_tensor,path_label)\n",
    "    count +=1\n",
    "    print (\"------------------\",count)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
